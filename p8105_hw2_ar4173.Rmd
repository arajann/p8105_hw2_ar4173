---
title: "p8105_hw2_ar4173"
author: "Anand Rajan"
date: "10/7/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library("readxl")
library(tidyr)
```

## Problem 1

Data Import and Cleaning of Trash Wheel Dataset

```{r message=FALSE}
trashwheel_data = 
read_excel("./data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx", sheet = "Mr. Trash Wheel") %>% 
janitor::clean_names() %>% 
select(-x15, -x16,-x17) %>% 
drop_na() %>% 
mutate(across(c(sports_balls), ~ round(., 0)))

median_balls =
  filter(trashwheel_data,
         year == "2019"
         ) 

median(median_balls$sports_balls)
```


Cleaning and Combining Precipitation data from 2018 and 2019


```{r}
prcp2018_data =
  read_excel("./data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx", 7, range="A2:B15") %>% 
  janitor::clean_names() %>% 
  mutate(year="2018")

prcp2019_data =
  read_excel("./data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx", 6, range="A2:B15") %>% 
  janitor::clean_names() %>% 
  mutate(year="2019")

prcp_data = 
  full_join(prcp2018_data, prcp2019_data, by="month") %>% 
  mutate(month=month.name[month])
  
```


```{r eval=FALSE}
Regarding the trash wheel dataset, there were a total of 453 observations in the tidy dataset. The trash wheel data set shows both the volume(in cubic yards) and weight (in tons) of the trash at each dumpster at a specific time points. Moreover the datset tells us the counts of different contents found in the dumpsters, such as cigarettes and sports balls. This allows us to take summary data of the measured contents in the dumpsters. For example, the median number of sports balls found in dumpsters in 2019 was 9 balls. Now regarding the precipitation data, the final joined dataset shows the total precipitation(in inches) of each month, stratified by year(13 observations). Thus we can see side by side how the total precipitation for example in April 2018 differs from April 2019.Additionally, the last row shows the total precipitation for each year. In 2018 the total precipitation was 70.33 inches, as opposed to 33.95 inches in 2019. 
```

## Problem 2

Cleaning Pols Dataset

```{r message=FALSE}
pols_data =
  read_csv(file= "./data/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(col = "mon",into= c("year","month","day"), sep ="-", remove = TRUE, convert = TRUE, extra = 'warn',fill='warn') %>%
  mutate(
    month= month.abb[month],
    president = recode(prez_gop, '1' = "gop", "0"="dem")
    ) %>% 
  select(-day, -prez_gop, -prez_dem)

```

Cleaning snp dataset

```{r message=FALSE}
snp_data =
  read_csv(file = "./data/snp.csv") %>% 
  janitor::clean_names() %>% 
  mutate(lubridate::mdy(date)) %>% 
  separate(col = "lubridate::mdy(date)",into = c("year","month","day"), sep = "-", remove = TRUE, convert = TRUE, extra = 'warn',fill='warn') %>%
  mutate(
    month= month.abb[month],
    year= if_else(year>2021, year-100, as.numeric(year))) %>% 
  select(-day, -date) %>% 
  relocate(year,month,close)
```

Cleaning Unemployment dataset

```{r message=FALSE}
unemployment_data =
  read_csv(file= "./data/unemployment.csv")


unemployment_tidy_data= 
  pivot_longer(
    unemployment_data,
    Jan:Dec,
    names_to= "month",
    values_to = "Percentage of Unemployment"
  )
```

Joining the Datasets

```{r}
temp_join =
  inner_join(snp_data,pols_data, by=c("year"="year","month"="month"))

poltics_success=
  inner_join(temp_join,unemployment_tidy_data,by=c("year"="Year","month"="month") )
```


```{r eval=FALSE}
The pols dataset shows us the breakdown of the number of congressional representitatives, congressional senators, and state governors by their political affiliation and the political party of the president  for every month from January 1947 to June 2015(822 observations in the dataset). In this data, we are only looking at the GOP and the Democratic party. The snp dataset tells us the closing values of the S%P stock index(close) for every month from January 1950 to July 2015(787 total observations in the dataset).Finally the tidy unemployment dataset shows us the precentage of unemployment for every month from January 1948 to June 2015(816 total observations). Thus the resulting combined dataset, politics success, gives us a snapshot of the what the stock market and job market looked like each month while showing us the political breakdown of the US during that month, i.e number of GOP senators, number of democrat governors, political affiliation of the president. The combined dataset gives us data from January 1950 to June 2015(786 total observations on 11 variables).

```

## Problem 3

Import and Tidy Baby Names dataset
```{r message=FALSE}
babynames =
  read_csv(file="./data/Popular_Baby_names.csv") %>%
  janitor::clean_names() %>%
  distinct(year_of_birth,ethnicity,childs_first_name,.keep_all=TRUE) %>% 
  mutate(
    ethnicity = replace(ethnicity, ethnicity=="BLACK NON HISP", "BLACK NON HISPANIC"),
    ethnicity = replace(ethnicity, ethnicity=="WHITE NON HISP", "WHITE NON HISPANIC"),
    ethnicity = replace(ethnicity, ethnicity=="ASIAN AND PACI", "ASIAN AND PACIFIC ISLANDER")
    )
  
```
Table thats shows the rank in popularity of the name Olivia over time

```{r}
olivia_df = pivot_wider(
  babynames,
  names_from = year_of_birth,
  values_from = rank
) %>% 
  filter(childs_first_name == "Olivia")

olivia_df
```


Table displaying the most popular name among male children over time

```{r}
male_df =
  filter(
  babynames,
  rank=="1",
  gender=="MALE"
  ) %>% 
  pivot_wider(
  names_from = year_of_birth ,
  values_from = rank
) %>% 
 janitor::clean_names()

male_df
```

Scatterplot that shows the # of Children with a name vs.  the rank in popularity

```{r}
male_2016 =
  filter(
    babynames,
    ethnicity == "WHITE NON HISPANIC",
    year_of_birth == "2016",
    gender == "MALE"
  )

ggplot(male_2016,aes(x=rank, y=count)) + geom_point() + 
  labs(
    title = "Populariy of Male Baby Names among White Non Hispanic Children in 2016",
    x= "Rank in Popularity of Baby Name",
    y="Number of Babies with Name")

```

